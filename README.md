# ğŸ›¡ï¸ AI Review Moderation 2.0  
**Explainable Trust & Safety Moderation (Rules + Lexicons + Semantic Neighbors)**

A lightweight, end-to-end demo for **review moderation** that combines:

âœ… Rule-based scoring  
âœ… Lexicon phrase matching  
âœ… Regex pattern detection (URL / email / phone / PII)  
âœ… Semantic similarity (vector neighbors)  
âœ… Explainable risk cards  
âœ… Human-in-the-loop routing (HITL)  

The system produces **flag/not-flag** decisions with:
- Human-readable explanations
- Triggered rules
- Matching phrases
- Similar past cases (when available)

---

## ğŸ› Architecture Overview

   User Text
      â†“
Text Preprocessing
      â†“
Phrase / Rule Matching  (weighted Î±)
      â†“
Semantic Neighbors     (weighted Î²)
      â†“
Score Blending (Î±Â·rules + Î²Â·neighbors)
      â†“
Decision Tiering (LOW / MEDIUM / HIGH)
      â†“
Explainability Cards


When full historical data is available, semantic neighbors boost signal quality.  
When data is restricted (privacy), the engine **gracefully degrades** into rule-only mode.

---

## ğŸ”§ Tech Stack

- **Frontend**: Streamlit
- **Reasoning Engine**: Python + lexicon scoring
- **Semantic Retrieval**: sentence-transformers + FAISS (optional)
- **Rules / Lexicons**: YAML (auditable, editable)
- **Documentation**: PRD, Model Card

(No raw data is included due to privacy constraints; see Degradation Modes below.)

---

## ğŸ—‚ Project Structure

app/
  decision.py          # core scoring engine
  neighbor.py          # FAISS wrapper + fallback
  rules.yml            # curated rules/lexicons
  rules_generated.yml  # auto-expanded lexicons
  sample_reviews.csv   # small public sample corpus (optional)
streamlit_app.py       # demo UI
docs/
  PRD.md
  model_card.md
notebooks/
  01_exploratory_iteration.ipynb
  02_rule_mining.ipynb
  03_lexicon_growth.ipynb

---

## ğŸš€ Quick Start

### 1) Environment
```bash
python -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt
```

### 2) Run UI
```bash
streamlit run streamlit_app.py
```

---


## ğŸ“¥ Data Requirements

### Optional
`sample_reviews.csv`

Used to build a tiny semantic index for neighbor scoring.

Replace with:
```bash
id,text,vote_reason_id
```
> Raw enterprise data is **not** included in this repo due to privacy.

---

## ğŸ§  Graceful Degradation (Important!)

This system supports **privacy-aware downgrade modes**:

| Mode    | Whatâ€™s Available         | Behavior                                      |
|---------|--------------------------|-----------------------------------------------|
| Full    | Raw historical corpus    | Rules + Lexicons + Semantic Neighbors         |
| Mid     | sample_reviews.csv only  | Local semantic similarity                     |
| Minimal | No corpus                | Pure rules engine (still explainable!)        |

High-signal categories remain stable:

- Promotion / Advertising
- Toxic / Harassment
- Privacy / PII
- COVID misinformation

Ambiguous categories (e.g., Off-topic) route to HITL (Human-In-The-Loop).

---

## ğŸ” Explainability Cards

For every decision, the UI shows:

- Category risk
- Extracted phrases
- Lexicon matches
- Regex hits (URL/email/phone)
- Neighbor evidence (when available)
- Final blended score

This makes decisions **auditable** and **transparent**.

---

## ğŸ§© Categories Covered

| vote_reason_id | Category               | Auto-manageable?                               |
|----------------|------------------------|------------------------------------------------|
| 2              | Off-topic              | âœ… (weak signal â†’ relies on neighbors)         |
| 6              | Toxic / Hate / Lewd    | âœ…                                             |
| 7              | Privacy / PII          | âœ…                                             |
| 8              | Promotional content    | âœ…                                             |
| 9              | COVID / misinformation | âœ…                                             |

Other flag types are intentionally **excluded** (not machine-verifiable).

---

## ğŸ“ˆ Evaluation

See `docs/model_card.md` for:

- precision / recall / F1
- false positive analysis
- category-wise breakdown

---

## ğŸ§ª Lexicon Growth (Auto-Mining)

Notebooks mine phrases using:

- log-odds ratio enrichment
- multi-gram extraction
- class-conditional frequency
- typo clustering

The engine expands:
```bash
rules_lexicons.yml
rules_generated.yml
```

These can be manually audited.

---

## ğŸ‘â€ğŸ—¨ Human-In-The-Loop (HITL)

Ambiguous scores route to human review:

- Score thresholding
- Confidence display
- Neighbor examples

This mimics real Trust & Safety queues.

---

## ğŸ” Privacy Notes

- Raw enterprise datasets are not stored in this repo
- Only synthetic/public sample CSV is included
- Model degradation preserves explainability

---

## ğŸ§¯ Risk / Failure Modes

- Off-topic ambiguity without semantic evidence
- Novel promotion tactics unseen in lexicon
- Evasive toxic slang evolution

Documented in the Model Card.

---

## ğŸ›  For Production

Add:

- Rate limiting
- AuthN/AuthZ
- Moderation queues
- Feedback loops
- Bias audits

---

## ğŸ‘€ Why This Matters (Pitch)

This repo demonstrates:

- Explainable moderation
- Auditable YAML rules
- Semantic retrieval (optional)
- Privacy-aware degradation
- Human-review queue routing
- Safe fallback behavior

Perfect for Meta / TikTok / YouTube Trust & Safety roles.

---

## ğŸ§³ Deployment

Works on:

- Local
- Streamlit Cloud
- GitHub Codespaces

`sample_reviews.csv` enables cloud mode without private data.

---

## ğŸ Status

âœ… Rule engine complete  
âœ… Lexicon auto-growth complete  
âœ… Explainability UI complete  
âœ… Degradation mode implemented  
â¬œ (Optional) raw corpus FAISS index  
â¬œ (Optional) admin review queue  

Even without raw embeddings, this is a shippable demo.

---

## ğŸ“œ License

MIT.  
Rules and lexicons are auditable and editable.


