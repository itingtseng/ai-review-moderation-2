{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "75be2139-469c-4975-89b3-a6f1814d9bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/tiffanytseng/Documents/ai-review-moderation-2/notebooks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9290c01a-ab78-4ee8-be70-4a1f8a570b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 專案根目錄: /Users/tiffanytseng/Documents/ai-review-moderation-2\n",
      "📁 RAW: /Users/tiffanytseng/Documents/ai-review-moderation-2/data/raw\n",
      "📁 PROC: /Users/tiffanytseng/Documents/ai-review-moderation-2/data/processed\n",
      "📁 LABELED: /Users/tiffanytseng/Documents/ai-review-moderation-2/data/labeled\n",
      "\n",
      "讀檔： /Users/tiffanytseng/Documents/ai-review-moderation-2/data/raw/exploratory_output.csv\n",
      "原始筆數： 32183\n",
      "\n",
      "✅ 原始筆數: 32183\n",
      "✅ 乾淨筆數: 30635\n",
      "✅ 刪除比例: 4.81 %\n",
      "\n",
      "💾 已輸出乾淨資料： /Users/tiffanytseng/Documents/ai-review-moderation-2/data/processed/clean_no_gibberish_dups.csv\n",
      "🗑️ 被刪資料： /Users/tiffanytseng/Documents/ai-review-moderation-2/data/processed/_dropped_rows.csv\n"
     ]
    }
   ],
   "source": [
    "# =============================================\n",
    "# 🧹 Step 1. 建立資料路徑 + 清理重複與亂文\n",
    "# =============================================\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# --- 自動偵測專案根目錄 ---\n",
    "ROOT = Path(os.getcwd()).parent          # e.g. /Users/tiffanytseng/Documents/ai-review-moderation-2\n",
    "DATA = ROOT / \"data\"\n",
    "RAW = DATA / \"raw\"\n",
    "PROC = DATA / \"processed\"\n",
    "LABELED = DATA / \"labeled\"\n",
    "\n",
    "# 確保資料夾存在\n",
    "PROC.mkdir(parents=True, exist_ok=True)\n",
    "LABELED.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"✅ 專案根目錄:\", ROOT)\n",
    "print(\"📁 RAW:\", RAW)\n",
    "print(\"📁 PROC:\", PROC)\n",
    "print(\"📁 LABELED:\", LABELED)\n",
    "\n",
    "# --- 讀取 01 的輸出 ---\n",
    "SRC = RAW / \"exploratory_output.csv\"\n",
    "print(\"\\n讀檔：\", SRC)\n",
    "\n",
    "df = pd.read_csv(SRC)\n",
    "print(\"原始筆數：\", len(df))\n",
    "\n",
    "# --- 轉換欄位型別（防止字串布林混亂） ---\n",
    "bool_cols = [\"_is_low_quality_v4\", \"_is_duplicate\"]\n",
    "for c in bool_cols:\n",
    "    if c in df.columns:\n",
    "        if df[c].dtype == \"O\":\n",
    "            df[c] = df[c].astype(str).str.lower().map({\"true\": True, \"false\": False})\n",
    "        df[c] = df[c].fillna(False).astype(bool)\n",
    "    else:\n",
    "        df[c] = False\n",
    "\n",
    "# --- gibberish 分數欄位 ---\n",
    "if \"_gibberish_score_v2\" not in df.columns:\n",
    "    df[\"_gibberish_score_v2\"] = 0.0\n",
    "df[\"_gibberish_score_v2\"] = pd.to_numeric(df[\"_gibberish_score_v2\"], errors=\"coerce\").fillna(0.0)\n",
    "\n",
    "# --- 清理條件 ---\n",
    "mask_clean = (\n",
    "    (~df[\"_is_low_quality_v4\"]) &\n",
    "    (~df[\"_is_duplicate\"]) &\n",
    "    (df[\"_gibberish_score_v2\"] < 0.5)\n",
    ")\n",
    "\n",
    "clean_df = df[mask_clean].copy()\n",
    "\n",
    "# --- 檢查數據 ---\n",
    "assert len(clean_df) <= len(df), \"❌ 乾淨筆數不應大於原始筆數。請檢查路徑或變數污染。\"\n",
    "\n",
    "print(\"\\n✅ 原始筆數:\", len(df))\n",
    "print(\"✅ 乾淨筆數:\", len(clean_df))\n",
    "print(\"✅ 刪除比例:\", round((1 - len(clean_df)/len(df)) * 100, 2), \"%\")\n",
    "\n",
    "# --- 匯出乾淨與被刪資料 ---\n",
    "clean_out = PROC / \"clean_no_gibberish_dups.csv\"\n",
    "dropped_out = PROC / \"_dropped_rows.csv\"\n",
    "\n",
    "clean_df.to_csv(clean_out, index=False)\n",
    "df.loc[~mask_clean].to_csv(dropped_out, index=False)\n",
    "\n",
    "print(\"\\n💾 已輸出乾淨資料：\", clean_out)\n",
    "print(\"🗑️ 被刪資料：\", dropped_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "91bd8a9c-2d64-430f-9c6e-c5b5419b9fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "讀取人工標註： /Users/tiffanytseng/Documents/ai-review-moderation-2/data/labeled/for_annotation.csv\n",
      "人工標註筆數：300 → 去重後：153\n",
      "\n",
      "Label 分佈：\n",
      "label\n",
      "real_apartment_review    136\n",
      "test_like                 17\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "real_apartment_review    88.89\n",
      "test_like                11.11\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "✅ 已輸出清理後標註檔： /Users/tiffanytseng/Documents/ai-review-moderation-2/data/labeled/for_annotation.cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# 路徑（你在 notebooks/ 底下）\n",
    "ROOT = Path.cwd().parent\n",
    "LABELED = ROOT / \"data\" / \"labeled\"\n",
    "PROC = ROOT / \"data\" / \"processed\"\n",
    "\n",
    "ANN = LABELED / \"for_annotation.csv\"\n",
    "print(\"讀取人工標註：\", ANN)\n",
    "ann = pd.read_csv(ANN)\n",
    "\n",
    "# --- 欄名正規化：去空白 -> 小寫 -> 空白轉底線 ---\n",
    "ann.columns = [c.strip().lower().replace(\" \", \"_\") for c in ann.columns]\n",
    "\n",
    "# --- 檢查必要欄位（label 用小寫）---\n",
    "need_cols = {\"object_id\",\"complex_id\",\"review_text\",\"label\"}\n",
    "missing = need_cols - set(ann.columns)\n",
    "if missing:\n",
    "    raise ValueError(f\"缺少欄位：{missing}（請在 for_annotation.csv 補上）\")\n",
    "\n",
    "# --- 清理 label 命名（先標準化，再合併 non-apartment -> test_like）---\n",
    "ann[\"label\"] = (\n",
    "    ann[\"label\"].astype(str).str.strip().str.lower()\n",
    "      .replace({\n",
    "          \"real-apartment-review\": \"real_apartment_review\",\n",
    "          \"real_apartment_review\": \"real_apartment_review\",\n",
    "          \"test-like\":            \"test_like\",\n",
    "          \"test_like\":            \"test_like\",\n",
    "          \"non-apartment\":        \"test_like\",      # 直接併入 test_like\n",
    "          \"non_apartment\":        \"test_like\",      # 直接併入 test_like\n",
    "      })\n",
    ")\n",
    "\n",
    "# --- 僅保留二類 ---\n",
    "allowed = {\"real_apartment_review\", \"test_like\"}\n",
    "ann = ann[ann[\"label\"].isin(allowed)].copy()\n",
    "\n",
    "# --- 文字簡單清理（不破壞語意）---\n",
    "def basic_clean(s: str) -> str:\n",
    "    return re.sub(r\"\\s+\", \" \", str(s)).strip()\n",
    "\n",
    "ann[\"review_text\"] = ann[\"review_text\"].map(basic_clean)\n",
    "\n",
    "# --- 以文字去重（你也可改成 [\"object_id\",\"review_text\"] 更嚴格）---\n",
    "before = len(ann)\n",
    "ann = ann.drop_duplicates(subset=[\"review_text\"]).copy()\n",
    "\n",
    "print(f\"人工標註筆數：{before} → 去重後：{len(ann)}\")\n",
    "print(\"\\nLabel 分佈：\")\n",
    "print(ann[\"label\"].value_counts())\n",
    "print((ann[\"label\"].value_counts(normalize=True)*100).round(2))\n",
    "\n",
    "# （可選）覆寫保存清理後的標註檔\n",
    "out_path = LABELED / \"for_annotation.cleaned.csv\"\n",
    "ann.to_csv(out_path, index=False)\n",
    "print(\"\\n✅ 已輸出清理後標註檔：\", out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "24b150a0-3839-4bbb-8de9-2474697576a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train 份量：117\n",
      "Label\n",
      "real_apartment_review    106\n",
      "test_like                 10\n",
      "non_apartment              1\n",
      "Name: count, dtype: int64\n",
      "Label\n",
      "real_apartment_review    90.60\n",
      "test_like                 8.55\n",
      "non_apartment             0.85\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Val 份量：25\n",
      "Label\n",
      "real_apartment_review    20\n",
      "test_like                 5\n",
      "Name: count, dtype: int64\n",
      "Label\n",
      "real_apartment_review    80.0\n",
      "test_like                20.0\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Test 份量：11\n",
      "Label\n",
      "real_apartment_review    10\n",
      "test_like                 1\n",
      "Name: count, dtype: int64\n",
      "Label\n",
      "real_apartment_review    90.91\n",
      "test_like                 9.09\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "✅ 已輸出：\n",
      " - data/labeled/train.csv\n",
      " - data/labeled/val.csv\n",
      " - data/labeled/test.csv\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from pathlib import Path\n",
    "\n",
    "# 以 complex_id 做群組，避免同社區同時在 train/val/test\n",
    "groups = ann[\"complex_id\"].astype(str)\n",
    "y = ann[\"Label\"]\n",
    "\n",
    "# train : temp(=val+test) = 80% : 20%\n",
    "gss1 = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "train_idx, temp_idx = next(gss1.split(ann, y, groups))\n",
    "\n",
    "train_df = ann.iloc[train_idx].copy()\n",
    "temp_df  = ann.iloc[temp_idx].copy()\n",
    "\n",
    "# temp 再劃分成 val : test = 50% : 50%（即各 10%）\n",
    "gss2 = GroupShuffleSplit(n_splits=1, test_size=0.5, random_state=42)\n",
    "val_idx, test_idx = next(gss2.split(temp_df, temp_df[\"Label\"], temp_df[\"complex_id\"].astype(str)))\n",
    "\n",
    "val_df  = temp_df.iloc[val_idx].copy()\n",
    "test_df = temp_df.iloc[test_idx].copy()\n",
    "\n",
    "# 確認分佈\n",
    "def show_dist(name, d):\n",
    "    print(f\"\\n{name} 份量：{len(d)}\")\n",
    "    print(d[\"Label\"].value_counts())\n",
    "    print((d[\"Label\"].value_counts(normalize=True)*100).round(2))\n",
    "\n",
    "for nm, d in [(\"Train\",train_df),(\"Val\",val_df),(\"Test\",test_df)]:\n",
    "    show_dist(nm, d)\n",
    "\n",
    "# 匯出\n",
    "LABELED.mkdir(parents=True, exist_ok=True)\n",
    "train_df.to_csv(LABELED / \"train.csv\", index=False)\n",
    "val_df.to_csv(LABELED / \"val.csv\", index=False)\n",
    "test_df.to_csv(LABELED / \"test.csv\", index=False)\n",
    "print(\"\\n✅ 已輸出：\")\n",
    "print(\" - data/labeled/train.csv\")\n",
    "print(\" - data/labeled/val.csv\")\n",
    "print(\" - data/labeled/test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "322d1b9c-9cea-4569-bb80-cd3266499b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_csv(\"../data/labeled/train.csv\")\n",
    "val_df   = pd.read_csv(\"../data/labeled/val.csv\")\n",
    "test_df  = pd.read_csv(\"../data/labeled/test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f51b9262-cffe-496c-9bde-f4f2193bc9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "讀取標註來源： /Users/tiffanytseng/Documents/ai-review-moderation-2/data/labeled/for_annotation.cleaned.csv\n",
      "總筆數： 153\n",
      "label\n",
      "real_apartment_review    136\n",
      "test_like                 17\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "ROOT = Path.cwd().parent\n",
    "LABELED = ROOT / \"data\" / \"labeled\"\n",
    "\n",
    "src_clean = LABELED / \"for_annotation.cleaned.csv\"\n",
    "src_raw   = LABELED / \"for_annotation.csv\"\n",
    "SRC = src_clean if src_clean.exists() else src_raw\n",
    "print(\"讀取標註來源：\", SRC)\n",
    "\n",
    "ann = pd.read_csv(SRC)\n",
    "\n",
    "# 欄名正規化\n",
    "ann.columns = [c.strip().lower().replace(\" \", \"_\") for c in ann.columns]\n",
    "\n",
    "# 檢查必要欄位\n",
    "need = {\"object_id\",\"complex_id\",\"review_text\",\"label\"}\n",
    "missing = need - set(ann.columns)\n",
    "if missing:\n",
    "    raise ValueError(f\"缺少欄位：{missing}\")\n",
    "\n",
    "# 僅二類\n",
    "ann[\"label\"] = ann[\"label\"].astype(str).str.strip().str.lower().replace({\n",
    "    \"non-apartment\": \"test_like\",\n",
    "    \"non_apartment\": \"test_like\",\n",
    "    \"real-apartment-review\": \"real_apartment_review\",\n",
    "})\n",
    "allowed = {\"real_apartment_review\",\"test_like\"}\n",
    "ann = ann[ann[\"label\"].isin(allowed)].copy()\n",
    "\n",
    "print(\"總筆數：\", len(ann))\n",
    "print(ann[\"label\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "63c90b5f-3e5e-43de-9daf-7146ce825d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train: 117\n",
      "label\n",
      "real_apartment_review    106\n",
      "test_like                 11\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "real_apartment_review    90.6\n",
      "test_like                 9.4\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Val: 21\n",
      "label\n",
      "real_apartment_review    20\n",
      "test_like                 1\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "real_apartment_review    95.24\n",
      "test_like                 4.76\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Test: 15\n",
      "label\n",
      "real_apartment_review    10\n",
      "test_like                 5\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "real_apartment_review    66.67\n",
      "test_like                33.33\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "✅ 已輸出 train/val/test 到 data/labeled/\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import numpy as np\n",
    "\n",
    "groups = ann[\"complex_id\"].astype(str)\n",
    "y = ann[\"label\"]\n",
    "\n",
    "def grouped_split(df, test_size=0.2, val_size=0.5, random_state=42, max_tries=100):\n",
    "    # 先切 train vs temp\n",
    "    for seed in range(random_state, random_state + max_tries):\n",
    "        gss1 = GroupShuffleSplit(n_splits=1, test_size=test_size, random_state=seed)\n",
    "        tr_idx, tmp_idx = next(gss1.split(df, df[\"label\"], df[\"complex_id\"].astype(str)))\n",
    "        train_df = df.iloc[tr_idx].copy()\n",
    "        tmp_df   = df.iloc[tmp_idx].copy()\n",
    "\n",
    "        # 再把 temp 切成 val/test\n",
    "        gss2 = GroupShuffleSplit(n_splits=1, test_size=val_size, random_state=seed+1)\n",
    "        v_idx, te_idx = next(gss2.split(tmp_df, tmp_df[\"label\"], tmp_df[\"complex_id\"].astype(str)))\n",
    "        val_df  = tmp_df.iloc[v_idx].copy()\n",
    "        test_df = tmp_df.iloc[te_idx].copy()\n",
    "\n",
    "        # 確保每個 split 都包含兩類\n",
    "        ok = (set(train_df[\"label\"].unique()) == {\"real_apartment_review\",\"test_like\"} and\n",
    "              set(val_df[\"label\"].unique())   == {\"real_apartment_review\",\"test_like\"} and\n",
    "              set(test_df[\"label\"].unique())  == {\"real_apartment_review\",\"test_like\"})\n",
    "        if ok:\n",
    "            return train_df, val_df, test_df\n",
    "\n",
    "    raise RuntimeError(\"分組抽樣多次仍無法讓每個 split 都含兩類；請增加樣本或調整比例。\")\n",
    "\n",
    "train_df, val_df, test_df = grouped_split(ann, test_size=0.2, val_size=0.5, random_state=42)\n",
    "\n",
    "def show_dist(name, d):\n",
    "    print(f\"\\n{name}: {len(d)}\")\n",
    "    print(d[\"label\"].value_counts())\n",
    "    print((d[\"label\"].value_counts(normalize=True)*100).round(2))\n",
    "\n",
    "show_dist(\"Train\", train_df)\n",
    "show_dist(\"Val\",   val_df)\n",
    "show_dist(\"Test\",  test_df)\n",
    "\n",
    "# 匯出\n",
    "train_df.to_csv(LABELED / \"train.csv\", index=False)\n",
    "val_df.to_csv(LABELED / \"val.csv\", index=False)\n",
    "test_df.to_csv(LABELED / \"test.csv\", index=False)\n",
    "print(\"\\n✅ 已輸出 train/val/test 到 data/labeled/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8e2d427e-b645-4cb7-a397-7c60412e6d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== VAL ===\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "real_apartment_review       1.00      1.00      1.00        20\n",
      "            test_like       1.00      1.00      1.00         1\n",
      "\n",
      "             accuracy                           1.00        21\n",
      "            macro avg       1.00      1.00      1.00        21\n",
      "         weighted avg       1.00      1.00      1.00        21\n",
      "\n",
      "ROC-AUC(test_like): 1.0\n",
      "\n",
      "=== TEST ===\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "real_apartment_review       0.77      1.00      0.87        10\n",
      "            test_like       1.00      0.40      0.57         5\n",
      "\n",
      "             accuracy                           0.80        15\n",
      "            macro avg       0.88      0.70      0.72        15\n",
      "         weighted avg       0.85      0.80      0.77        15\n",
      "\n",
      "ROC-AUC(test_like): 0.96\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>real_apartment_review</th>\n",
       "      <th>test_like</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>real_apartment_review</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_like</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       real_apartment_review  test_like\n",
       "real_apartment_review                     10          0\n",
       "test_like                                  3          2"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "X_train, y_train = train_df[\"review_text\"].astype(str), train_df[\"label\"].astype(str)\n",
    "X_val,   y_val   = val_df[\"review_text\"].astype(str),   val_df[\"label\"].astype(str)\n",
    "X_test,  y_test  = test_df[\"review_text\"].astype(str),  test_df[\"label\"].astype(str)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(\n",
    "        ngram_range=(1,2),\n",
    "        min_df=2,\n",
    "        max_df=0.98,\n",
    "        sublinear_tf=True\n",
    "    )),\n",
    "    (\"clf\", LogisticRegression(\n",
    "        max_iter=2000,\n",
    "        class_weight=\"balanced\",\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "def eval_split(name, X, y):\n",
    "    pred = pipe.predict(X)\n",
    "    proba = pipe.predict_proba(X)[:, pipe.classes_.tolist().index(\"test_like\")]  # 取 test_like 的機率\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(classification_report(y, pred, target_names=[\"real_apartment_review\",\"test_like\"], zero_division=0))\n",
    "    try:\n",
    "        auc = roc_auc_score((y==\"test_like\").astype(int), proba)\n",
    "        print(\"ROC-AUC(test_like):\", round(auc, 4))\n",
    "    except Exception as e:\n",
    "        print(\"ROC-AUC 無法計算：\", e)\n",
    "    return pred, proba\n",
    "\n",
    "pred_val,  proba_val  = eval_split(\"VAL\",  X_val,  y_val)\n",
    "pred_test, proba_test = eval_split(\"TEST\", X_test, y_test)\n",
    "\n",
    "# 混淆矩陣（test）\n",
    "cm = confusion_matrix(y_test, pred_test, labels=[\"real_apartment_review\",\"test_like\"])\n",
    "cm_df = pd.DataFrame(cm, index=[\"real_apartment_review\",\"test_like\"], columns=[\"real_apartment_review\",\"test_like\"])\n",
    "cm_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "66cfc5cc-4c7a-479e-8c04-aee5968f35b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "未標註池大小： 30355\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "ROOT = Path.cwd().parent\n",
    "PROC = ROOT / \"data\" / \"processed\"\n",
    "LABELED = ROOT / \"data\" / \"labeled\"\n",
    "\n",
    "clean_path = PROC / \"clean_no_gibberish_dups.csv\"\n",
    "ann_path   = LABELED / \"for_annotation.cleaned.csv\"\n",
    "\n",
    "pool = pd.read_csv(clean_path)\n",
    "pool.columns = [c.strip().lower().replace(\" \", \"_\") for c in pool.columns]\n",
    "\n",
    "if ann_path.exists():\n",
    "    ann = pd.read_csv(ann_path)\n",
    "else:\n",
    "    ann = pd.read_csv(LABELED / \"for_annotation.csv\")\n",
    "ann.columns = [c.strip().lower().replace(\" \", \"_\") for c in ann.columns]\n",
    "\n",
    "labeled_ids = set(ann[\"object_id\"].astype(str))\n",
    "pool = pool[~pool[\"object_id\"].astype(str).isin(labeled_ids)].copy()\n",
    "print(\"未標註池大小：\", len(pool))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2b8375ce-10af-4a5b-9201-a0cc6eb116eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>object_id</th>\n",
       "      <th>complex_id</th>\n",
       "      <th>review_text</th>\n",
       "      <th>_proba_test_like</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5732</th>\n",
       "      <td>111700287</td>\n",
       "      <td>3101234567</td>\n",
       "      <td>x Be Specific - Don&amp;apos;t just complain about...</td>\n",
       "      <td>0.783889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26986</th>\n",
       "      <td>112082546</td>\n",
       "      <td>9199332346275143593</td>\n",
       "      <td>n/a ehh not applicableMillions of people use  ...</td>\n",
       "      <td>0.711205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6548</th>\n",
       "      <td>112685038</td>\n",
       "      <td>410356506221117</td>\n",
       "      <td>Please I don't want to complete this section.M...</td>\n",
       "      <td>0.686399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20064</th>\n",
       "      <td>217700</td>\n",
       "      <td>281890283977070</td>\n",
       "      <td>Not a great choice</td>\n",
       "      <td>0.681807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>112823250</td>\n",
       "      <td>9199332346275192547</td>\n",
       "      <td>JOE TEST Anon - Lorem ipsum dolor sit amet, co...</td>\n",
       "      <td>0.614671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       object_id           complex_id  \\\n",
       "5732   111700287           3101234567   \n",
       "26986  112082546  9199332346275143593   \n",
       "6548   112685038      410356506221117   \n",
       "20064     217700      281890283977070   \n",
       "270    112823250  9199332346275192547   \n",
       "\n",
       "                                             review_text  _proba_test_like  \n",
       "5732   x Be Specific - Don&apos;t just complain about...          0.783889  \n",
       "26986  n/a ehh not applicableMillions of people use  ...          0.711205  \n",
       "6548   Please I don't want to complete this section.M...          0.686399  \n",
       "20064                                 Not a great choice          0.681807  \n",
       "270    JOE TEST Anon - Lorem ipsum dolor sit amet, co...          0.614671  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 取得 \"test_like\" 在 pipe.classes_ 的 index\n",
    "classes = pipe.classes_.tolist()\n",
    "assert \"test_like\" in classes, f\"你的模型類別：{classes}，找不到 'test_like'。\"\n",
    "ti = classes.index(\"test_like\")\n",
    "\n",
    "# 對未標註池預測\n",
    "proba = pipe.predict_proba(pool[\"review_text\"].astype(str))[:, ti]\n",
    "pool[\"_proba_test_like\"] = proba\n",
    "\n",
    "# 方便人工標註的欄位子集\n",
    "view_cols = [\"object_id\",\"complex_id\",\"review_text\",\"_proba_test_like\"]\n",
    "pool_preview = pool[view_cols].copy().sort_values(\"_proba_test_like\", ascending=False)\n",
    "pool_preview.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ffa3da91-0f29-464c-b1b3-29bf8263f053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 已輸出：\n",
      " - /Users/tiffanytseng/Documents/ai-review-moderation-2/data/labeled/round2_candidates_highprob.csv\n",
      " - /Users/tiffanytseng/Documents/ai-review-moderation-2/data/labeled/round2_candidates_uncertain.csv\n",
      " - /Users/tiffanytseng/Documents/ai-review-moderation-2/data/labeled/round2_candidates_from_dropped.csv\n",
      "合計候選： 0 + 200 + 200\n"
     ]
    }
   ],
   "source": [
    "# 1) 高機率 test_like（建議快速標記：幾乎都是）\n",
    "hi = pool_preview.query(\"_proba_test_like >= 0.80\").head(200)\n",
    "\n",
    "# 2) 不確定區（模型最需要你提供訊息）\n",
    "uncertain = pool_preview.query(\"_proba_test_like >= 0.40 and _proba_test_like <= 0.60\").head(200)\n",
    "\n",
    "# 3) 從被刪清單回收（多半是亂文/模板）\n",
    "dropped = pd.read_csv(PROC / \"_dropped_rows.csv\")\n",
    "dropped.columns = [c.strip().lower().replace(\" \", \"_\") for c in dropped.columns]\n",
    "pick_cols = [c for c in view_cols if c in dropped.columns] + [c for c in [\"_gibberish_score_v2\",\"_is_low_quality_v4\"] if c in dropped.columns]\n",
    "dropped_preview = dropped[pick_cols].copy()\n",
    "# 取亂文較高或被標為低品質者\n",
    "if \"_gibberish_score_v2\" in dropped_preview:\n",
    "    backfill = dropped_preview.sort_values(\"_gibberish_score_v2\", ascending=False).head(200)\n",
    "else:\n",
    "    backfill = dropped_preview.head(200)\n",
    "\n",
    "# 輸出成待標註 CSV\n",
    "LABELED.mkdir(parents=True, exist_ok=True)\n",
    "hi_out   = LABELED / \"round2_candidates_highprob.csv\"\n",
    "unc_out  = LABELED / \"round2_candidates_uncertain.csv\"\n",
    "drop_out = LABELED / \"round2_candidates_from_dropped.csv\"\n",
    "\n",
    "hi.to_csv(hi_out, index=False)\n",
    "uncertain.to_csv(unc_out, index=False)\n",
    "backfill.to_csv(drop_out, index=False)\n",
    "\n",
    "print(\"✅ 已輸出：\")\n",
    "print(\" -\", hi_out)\n",
    "print(\" -\", unc_out)\n",
    "print(\" -\", drop_out)\n",
    "print(\"合計候選：\", len(hi), \"+\", len(uncertain), \"+\", len(backfill))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "76e0103d-adf6-4129-b3c5-1763b9693bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 已輸出新的標註全集： /Users/tiffanytseng/Documents/ai-review-moderation-2/data/labeled/for_annotation.cleaned.v2.csv\n",
      "label\n",
      "real_apartment_review    136\n",
      "test_like                 17\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "ROOT = Path.cwd().parent\n",
    "LABELED = ROOT / \"data\" / \"labeled\"\n",
    "\n",
    "# 讀原標註\n",
    "base = pd.read_csv(LABELED / \"for_annotation.cleaned.csv\")\n",
    "base.columns = [c.strip().lower().replace(\" \", \"_\") for c in base.columns]\n",
    "\n",
    "# 讀回合併\n",
    "parts = []\n",
    "for name in [\"round2_labeled_highprob.csv\", \"round2_labeled_uncertain.csv\", \"round2_labeled_dropped.csv\"]:\n",
    "    p = LABELED / name\n",
    "    if p.exists():\n",
    "        d = pd.read_csv(p)\n",
    "        d.columns = [c.strip().lower().replace(\" \", \"_\") for c in d.columns]\n",
    "        # 確保有 label 欄\n",
    "        if \"label\" not in d.columns:\n",
    "            raise ValueError(f\"{name} 缺少 label 欄位\")\n",
    "        parts.append(d[[\"object_id\",\"complex_id\",\"review_text\",\"label\"]])\n",
    "\n",
    "add = pd.concat(parts, ignore_index=True) if parts else pd.DataFrame(columns=[\"object_id\",\"complex_id\",\"review_text\",\"label\"])\n",
    "\n",
    "# 合併 & 去重（以 text 去重）\n",
    "merged = pd.concat([base[[\"object_id\",\"complex_id\",\"review_text\",\"label\"]], add], ignore_index=True)\n",
    "merged[\"label\"] = merged[\"label\"].astype(str).str.strip().str.lower().replace({\n",
    "    \"non-apartment\":\"test_like\",\"non_apartment\":\"test_like\",\n",
    "    \"real-apartment-review\":\"real_apartment_review\"\n",
    "})\n",
    "merged = merged.drop_duplicates(subset=[\"review_text\"]).copy()\n",
    "\n",
    "# 覆寫 cleaned v2\n",
    "out = LABELED / \"for_annotation.cleaned.v2.csv\"\n",
    "merged.to_csv(out, index=False)\n",
    "print(\"✅ 已輸出新的標註全集：\", out)\n",
    "print(merged[\"label\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0f979835-8a51-413f-9866-33d0a09f65b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== VAL ===\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "real_apartment_review       0.95      1.00      0.98        20\n",
      "            test_like       0.00      0.00      0.00         1\n",
      "\n",
      "             accuracy                           0.95        21\n",
      "            macro avg       0.48      0.50      0.49        21\n",
      "         weighted avg       0.91      0.95      0.93        21\n",
      "\n",
      "ROC-AUC(test_like): 1.0\n",
      "\n",
      "=== TEST ===\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "real_apartment_review       0.67      1.00      0.80        10\n",
      "            test_like       0.00      0.00      0.00         5\n",
      "\n",
      "             accuracy                           0.67        15\n",
      "            macro avg       0.33      0.50      0.40        15\n",
      "         weighted avg       0.44      0.67      0.53        15\n",
      "\n",
      "ROC-AUC(test_like): 0.96\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>real_apartment_review</th>\n",
       "      <th>test_like</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>real_apartment_review</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_like</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       real_apartment_review  test_like\n",
       "real_apartment_review                     10          0\n",
       "test_like                                  5          0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "ann = pd.read_csv(LABELED / \"for_annotation.cleaned.v2.csv\")\n",
    "ann.columns = [c.strip().lower().replace(\" \", \"_\") for c in ann.columns]\n",
    "\n",
    "# 分組切分（確保每個 split 兩類都有）\n",
    "def grouped_split(df, test_size=0.2, val_size=0.5, random_state=42, tries=100):\n",
    "    for seed in range(random_state, random_state+tries):\n",
    "        g1 = GroupShuffleSplit(n_splits=1, test_size=test_size, random_state=seed)\n",
    "        tr_idx, tmp_idx = next(g1.split(df, df[\"label\"], df[\"complex_id\"].astype(str)))\n",
    "        train_df, tmp_df = df.iloc[tr_idx].copy(), df.iloc[tmp_idx].copy()\n",
    "        g2 = GroupShuffleSplit(n_splits=1, test_size=val_size, random_state=seed+1)\n",
    "        v_idx, te_idx = next(g2.split(tmp_df, tmp_df[\"label\"], tmp_df[\"complex_id\"].astype(str)))\n",
    "        val_df, test_df = tmp_df.iloc[v_idx].copy(), tmp_df.iloc[te_idx].copy()\n",
    "        if all(set(d[\"label\"].unique())=={\"real_apartment_review\",\"test_like\"} for d in [train_df,val_df,test_df]):\n",
    "            return train_df, val_df, test_df\n",
    "    raise RuntimeError(\"無法讓每個 split 都含兩類，請增加樣本或調比例。\")\n",
    "\n",
    "train_df, val_df, test_df = grouped_split(ann)\n",
    "\n",
    "X_train, y_train = train_df[\"review_text\"].astype(str), train_df[\"label\"].astype(str)\n",
    "X_val,   y_val   = val_df[\"review_text\"].astype(str),   val_df[\"label\"].astype(str)\n",
    "X_test,  y_test  = test_df[\"review_text\"].astype(str),  test_df[\"label\"].astype(str)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(ngram_range=(1,2), min_df=2, max_df=0.98, sublinear_tf=True)),\n",
    "    (\"clf\", LogisticRegression(max_iter=2000, class_weight={\"real_apartment_review\":0.8,\"test_like\":1.2}, n_jobs=-1))\n",
    "]).fit(X_train, y_train)\n",
    "\n",
    "def eval_split(name, X, y):\n",
    "    pred = pipe.predict(X)\n",
    "    proba = pipe.predict_proba(X)[:, pipe.classes_.tolist().index(\"test_like\")]\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(classification_report(y, pred, target_names=[\"real_apartment_review\",\"test_like\"], zero_division=0))\n",
    "    try:\n",
    "        print(\"ROC-AUC(test_like):\", round(roc_auc_score((y==\"test_like\").astype(int), proba), 4))\n",
    "    except: pass\n",
    "    return pred, proba\n",
    "\n",
    "pred_val,  proba_val  = eval_split(\"VAL\",  X_val,  y_val)\n",
    "pred_test, proba_test = eval_split(\"TEST\", X_test, y_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, pred_test, labels=[\"real_apartment_review\",\"test_like\"])\n",
    "pd.DataFrame(cm, index=[\"real_apartment_review\",\"test_like\"], columns=[\"real_apartment_review\",\"test_like\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "df523fff-948a-40f5-aa27-3d5e6fbdeaee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "存在檢查：\n",
      "- for_annotation.cleaned.csv      exists=True  mtime=2025-10-22 15:08:56\n",
      "- round2_labeled_uncertain.csv    exists=False  mtime=N/A\n",
      "- round2_labeled_highprob.csv     exists=False  mtime=N/A\n",
      "- round2_labeled_dropped.csv      exists=False  mtime=N/A\n",
      "- for_annotation.cleaned.v2.csv   exists=True  mtime=2025-10-22 15:42:39\n",
      "\n",
      "✅ v2 筆數： 153\n",
      "✅ v2 標籤分佈：\n",
      "label\n",
      "real_apartment_review    136\n",
      "test_like                 17\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd, time\n",
    "\n",
    "ROOT = Path.cwd().parent\n",
    "LABELED = ROOT / \"data\" / \"labeled\"\n",
    "\n",
    "v2 = LABELED / \"for_annotation.cleaned.v2.csv\"\n",
    "base = LABELED / \"for_annotation.cleaned.csv\"\n",
    "r2u  = LABELED / \"round2_labeled_uncertain.csv\"\n",
    "r2h  = LABELED / \"round2_labeled_highprob.csv\"\n",
    "r2d  = LABELED / \"round2_labeled_dropped.csv\"\n",
    "\n",
    "def mtime(p): \n",
    "    return time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(p.stat().st_mtime)) if p.exists() else \"N/A\"\n",
    "\n",
    "print(\"存在檢查：\")\n",
    "for p in [base, r2u, r2h, r2d, v2]:\n",
    "    print(f\"- {p.name:30s}  exists={p.exists()}  mtime={mtime(p)}\")\n",
    "\n",
    "if v2.exists():\n",
    "    ann = pd.read_csv(v2)\n",
    "    ann.columns = [c.strip().lower().replace(\" \", \"_\") for c in ann.columns]\n",
    "    print(\"\\n✅ v2 筆數：\", len(ann))\n",
    "    print(\"✅ v2 標籤分佈：\")\n",
    "    print(ann[\"label\"].value_counts())\n",
    "else:\n",
    "    print(\"\\n⚠️ 目前沒有 v2，代表合併步驟尚未完成（或沒輸出）。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "71447c79-0a60-48e1-bbc9-360375f43bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 分佈：\n",
      "label\n",
      "real_apartment_review    106\n",
      "test_like                 11\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Val 分佈：\n",
      "label\n",
      "real_apartment_review    20\n",
      "test_like                 1\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Test 分佈：\n",
      "label\n",
      "real_apartment_review    10\n",
      "test_like                 5\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "\n",
      "=== VAL ===\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "real_apartment_review       0.95      1.00      0.98        20\n",
      "            test_like       0.00      0.00      0.00         1\n",
      "\n",
      "             accuracy                           0.95        21\n",
      "            macro avg       0.48      0.50      0.49        21\n",
      "         weighted avg       0.91      0.95      0.93        21\n",
      "\n",
      "\n",
      "=== TEST ===\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "real_apartment_review       0.67      1.00      0.80        10\n",
      "            test_like       0.00      0.00      0.00         5\n",
      "\n",
      "             accuracy                           0.67        15\n",
      "            macro avg       0.33      0.50      0.40        15\n",
      "         weighted avg       0.44      0.67      0.53        15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "ann = pd.read_csv(LABELED / \"for_annotation.cleaned.v2.csv\")\n",
    "ann.columns = [c.strip().lower().replace(\" \", \"_\") for c in ann.columns]\n",
    "\n",
    "def grouped_split(df, test_size=0.2, val_size=0.5, random_state=42, tries=100):\n",
    "    for seed in range(random_state, random_state+tries):\n",
    "        g1 = GroupShuffleSplit(n_splits=1, test_size=test_size, random_state=seed)\n",
    "        tr_idx, tmp_idx = next(g1.split(df, df[\"label\"], df[\"complex_id\"].astype(str)))\n",
    "        train_df, tmp_df = df.iloc[tr_idx].copy(), df.iloc[tmp_idx].copy()\n",
    "        g2 = GroupShuffleSplit(n_splits=1, test_size=val_size, random_state=seed+1)\n",
    "        v_idx, te_idx = next(g2.split(tmp_df, tmp_df[\"label\"], tmp_df[\"complex_id\"].astype(str)))\n",
    "        val_df, test_df = tmp_df.iloc[v_idx].copy(), tmp_df.iloc[te_idx].copy()\n",
    "        if all(set(d[\"label\"].unique())=={\"real_apartment_review\",\"test_like\"} for d in [train_df,val_df,test_df]):\n",
    "            return train_df, val_df, test_df\n",
    "    raise RuntimeError(\"split 無法滿足每組含兩類，請增加 test_like 或調整比例。\")\n",
    "\n",
    "train_df, val_df, test_df = grouped_split(ann)\n",
    "\n",
    "# 檢查各 split 的 test_like 數量是否真的增加\n",
    "for nm, d in [(\"Train\",train_df),(\"Val\",val_df),(\"Test\",test_df)]:\n",
    "    print(nm, \"分佈：\")\n",
    "    print(d[\"label\"].value_counts(), \"\\n\")\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(ngram_range=(1,2), min_df=2, max_df=0.98, sublinear_tf=True)),\n",
    "    (\"clf\", LogisticRegression(max_iter=2000, class_weight={\"real_apartment_review\":0.8,\"test_like\":1.2}, n_jobs=-1))\n",
    "]).fit(train_df[\"review_text\"].astype(str), train_df[\"label\"].astype(str))\n",
    "\n",
    "def eval_split(name, X, y):\n",
    "    pred = pipe.predict(X)\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(classification_report(y, pred, target_names=[\"real_apartment_review\",\"test_like\"], zero_division=0))\n",
    "    return pred\n",
    "\n",
    "_ = eval_split(\"VAL\",  val_df[\"review_text\"].astype(str),  val_df[\"label\"].astype(str))\n",
    "_ = eval_split(\"TEST\", test_df[\"review_text\"].astype(str), test_df[\"label\"].astype(str))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa152bd-b611-465b-b552-a1015f56b335",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (.venv311)",
   "language": "python",
   "name": "ai311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
