{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "75be2139-469c-4975-89b3-a6f1814d9bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/tiffanytseng/Documents/ai-review-moderation-2/notebooks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9290c01a-ab78-4ee8-be70-4a1f8a570b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… å°ˆæ¡ˆæ ¹ç›®éŒ„: /Users/tiffanytseng/Documents/ai-review-moderation-2\n",
      "ğŸ“ RAW: /Users/tiffanytseng/Documents/ai-review-moderation-2/data/raw\n",
      "ğŸ“ PROC: /Users/tiffanytseng/Documents/ai-review-moderation-2/data/processed\n",
      "ğŸ“ LABELED: /Users/tiffanytseng/Documents/ai-review-moderation-2/data/labeled\n",
      "\n",
      "è®€æª”ï¼š /Users/tiffanytseng/Documents/ai-review-moderation-2/data/raw/exploratory_output.csv\n",
      "åŸå§‹ç­†æ•¸ï¼š 32183\n",
      "\n",
      "âœ… åŸå§‹ç­†æ•¸: 32183\n",
      "âœ… ä¹¾æ·¨ç­†æ•¸: 30635\n",
      "âœ… åˆªé™¤æ¯”ä¾‹: 4.81 %\n",
      "\n",
      "ğŸ’¾ å·²è¼¸å‡ºä¹¾æ·¨è³‡æ–™ï¼š /Users/tiffanytseng/Documents/ai-review-moderation-2/data/processed/clean_no_gibberish_dups.csv\n",
      "ğŸ—‘ï¸ è¢«åˆªè³‡æ–™ï¼š /Users/tiffanytseng/Documents/ai-review-moderation-2/data/processed/_dropped_rows.csv\n"
     ]
    }
   ],
   "source": [
    "# =============================================\n",
    "# ğŸ§¹ Step 1. å»ºç«‹è³‡æ–™è·¯å¾‘ + æ¸…ç†é‡è¤‡èˆ‡äº‚æ–‡\n",
    "# =============================================\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# --- è‡ªå‹•åµæ¸¬å°ˆæ¡ˆæ ¹ç›®éŒ„ ---\n",
    "ROOT = Path(os.getcwd()).parent          # e.g. /Users/tiffanytseng/Documents/ai-review-moderation-2\n",
    "DATA = ROOT / \"data\"\n",
    "RAW = DATA / \"raw\"\n",
    "PROC = DATA / \"processed\"\n",
    "LABELED = DATA / \"labeled\"\n",
    "\n",
    "# ç¢ºä¿è³‡æ–™å¤¾å­˜åœ¨\n",
    "PROC.mkdir(parents=True, exist_ok=True)\n",
    "LABELED.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"âœ… å°ˆæ¡ˆæ ¹ç›®éŒ„:\", ROOT)\n",
    "print(\"ğŸ“ RAW:\", RAW)\n",
    "print(\"ğŸ“ PROC:\", PROC)\n",
    "print(\"ğŸ“ LABELED:\", LABELED)\n",
    "\n",
    "# --- è®€å– 01 çš„è¼¸å‡º ---\n",
    "SRC = RAW / \"exploratory_output.csv\"\n",
    "print(\"\\nè®€æª”ï¼š\", SRC)\n",
    "\n",
    "df = pd.read_csv(SRC)\n",
    "print(\"åŸå§‹ç­†æ•¸ï¼š\", len(df))\n",
    "\n",
    "# --- è½‰æ›æ¬„ä½å‹åˆ¥ï¼ˆé˜²æ­¢å­—ä¸²å¸ƒæ—æ··äº‚ï¼‰ ---\n",
    "bool_cols = [\"_is_low_quality_v4\", \"_is_duplicate\"]\n",
    "for c in bool_cols:\n",
    "    if c in df.columns:\n",
    "        if df[c].dtype == \"O\":\n",
    "            df[c] = df[c].astype(str).str.lower().map({\"true\": True, \"false\": False})\n",
    "        df[c] = df[c].fillna(False).astype(bool)\n",
    "    else:\n",
    "        df[c] = False\n",
    "\n",
    "# --- gibberish åˆ†æ•¸æ¬„ä½ ---\n",
    "if \"_gibberish_score_v2\" not in df.columns:\n",
    "    df[\"_gibberish_score_v2\"] = 0.0\n",
    "df[\"_gibberish_score_v2\"] = pd.to_numeric(df[\"_gibberish_score_v2\"], errors=\"coerce\").fillna(0.0)\n",
    "\n",
    "# --- æ¸…ç†æ¢ä»¶ ---\n",
    "mask_clean = (\n",
    "    (~df[\"_is_low_quality_v4\"]) &\n",
    "    (~df[\"_is_duplicate\"]) &\n",
    "    (df[\"_gibberish_score_v2\"] < 0.5)\n",
    ")\n",
    "\n",
    "clean_df = df[mask_clean].copy()\n",
    "\n",
    "# --- æª¢æŸ¥æ•¸æ“š ---\n",
    "assert len(clean_df) <= len(df), \"âŒ ä¹¾æ·¨ç­†æ•¸ä¸æ‡‰å¤§æ–¼åŸå§‹ç­†æ•¸ã€‚è«‹æª¢æŸ¥è·¯å¾‘æˆ–è®Šæ•¸æ±¡æŸ“ã€‚\"\n",
    "\n",
    "print(\"\\nâœ… åŸå§‹ç­†æ•¸:\", len(df))\n",
    "print(\"âœ… ä¹¾æ·¨ç­†æ•¸:\", len(clean_df))\n",
    "print(\"âœ… åˆªé™¤æ¯”ä¾‹:\", round((1 - len(clean_df)/len(df)) * 100, 2), \"%\")\n",
    "\n",
    "# --- åŒ¯å‡ºä¹¾æ·¨èˆ‡è¢«åˆªè³‡æ–™ ---\n",
    "clean_out = PROC / \"clean_no_gibberish_dups.csv\"\n",
    "dropped_out = PROC / \"_dropped_rows.csv\"\n",
    "\n",
    "clean_df.to_csv(clean_out, index=False)\n",
    "df.loc[~mask_clean].to_csv(dropped_out, index=False)\n",
    "\n",
    "print(\"\\nğŸ’¾ å·²è¼¸å‡ºä¹¾æ·¨è³‡æ–™ï¼š\", clean_out)\n",
    "print(\"ğŸ—‘ï¸ è¢«åˆªè³‡æ–™ï¼š\", dropped_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "91bd8a9c-2d64-430f-9c6e-c5b5419b9fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®€å–äººå·¥æ¨™è¨»ï¼š /Users/tiffanytseng/Documents/ai-review-moderation-2/data/labeled/for_annotation.csv\n",
      "äººå·¥æ¨™è¨»ç­†æ•¸ï¼š300 â†’ å»é‡å¾Œï¼š153\n",
      "\n",
      "Label åˆ†ä½ˆï¼š\n",
      "label\n",
      "real_apartment_review    136\n",
      "test_like                 17\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "real_apartment_review    88.89\n",
      "test_like                11.11\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "âœ… å·²è¼¸å‡ºæ¸…ç†å¾Œæ¨™è¨»æª”ï¼š /Users/tiffanytseng/Documents/ai-review-moderation-2/data/labeled/for_annotation.cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# è·¯å¾‘ï¼ˆä½ åœ¨ notebooks/ åº•ä¸‹ï¼‰\n",
    "ROOT = Path.cwd().parent\n",
    "LABELED = ROOT / \"data\" / \"labeled\"\n",
    "PROC = ROOT / \"data\" / \"processed\"\n",
    "\n",
    "ANN = LABELED / \"for_annotation.csv\"\n",
    "print(\"è®€å–äººå·¥æ¨™è¨»ï¼š\", ANN)\n",
    "ann = pd.read_csv(ANN)\n",
    "\n",
    "# --- æ¬„åæ­£è¦åŒ–ï¼šå»ç©ºç™½ -> å°å¯« -> ç©ºç™½è½‰åº•ç·š ---\n",
    "ann.columns = [c.strip().lower().replace(\" \", \"_\") for c in ann.columns]\n",
    "\n",
    "# --- æª¢æŸ¥å¿…è¦æ¬„ä½ï¼ˆlabel ç”¨å°å¯«ï¼‰---\n",
    "need_cols = {\"object_id\",\"complex_id\",\"review_text\",\"label\"}\n",
    "missing = need_cols - set(ann.columns)\n",
    "if missing:\n",
    "    raise ValueError(f\"ç¼ºå°‘æ¬„ä½ï¼š{missing}ï¼ˆè«‹åœ¨ for_annotation.csv è£œä¸Šï¼‰\")\n",
    "\n",
    "# --- æ¸…ç† label å‘½åï¼ˆå…ˆæ¨™æº–åŒ–ï¼Œå†åˆä½µ non-apartment -> test_likeï¼‰---\n",
    "ann[\"label\"] = (\n",
    "    ann[\"label\"].astype(str).str.strip().str.lower()\n",
    "      .replace({\n",
    "          \"real-apartment-review\": \"real_apartment_review\",\n",
    "          \"real_apartment_review\": \"real_apartment_review\",\n",
    "          \"test-like\":            \"test_like\",\n",
    "          \"test_like\":            \"test_like\",\n",
    "          \"non-apartment\":        \"test_like\",      # ç›´æ¥ä½µå…¥ test_like\n",
    "          \"non_apartment\":        \"test_like\",      # ç›´æ¥ä½µå…¥ test_like\n",
    "      })\n",
    ")\n",
    "\n",
    "# --- åƒ…ä¿ç•™äºŒé¡ ---\n",
    "allowed = {\"real_apartment_review\", \"test_like\"}\n",
    "ann = ann[ann[\"label\"].isin(allowed)].copy()\n",
    "\n",
    "# --- æ–‡å­—ç°¡å–®æ¸…ç†ï¼ˆä¸ç ´å£èªæ„ï¼‰---\n",
    "def basic_clean(s: str) -> str:\n",
    "    return re.sub(r\"\\s+\", \" \", str(s)).strip()\n",
    "\n",
    "ann[\"review_text\"] = ann[\"review_text\"].map(basic_clean)\n",
    "\n",
    "# --- ä»¥æ–‡å­—å»é‡ï¼ˆä½ ä¹Ÿå¯æ”¹æˆ [\"object_id\",\"review_text\"] æ›´åš´æ ¼ï¼‰---\n",
    "before = len(ann)\n",
    "ann = ann.drop_duplicates(subset=[\"review_text\"]).copy()\n",
    "\n",
    "print(f\"äººå·¥æ¨™è¨»ç­†æ•¸ï¼š{before} â†’ å»é‡å¾Œï¼š{len(ann)}\")\n",
    "print(\"\\nLabel åˆ†ä½ˆï¼š\")\n",
    "print(ann[\"label\"].value_counts())\n",
    "print((ann[\"label\"].value_counts(normalize=True)*100).round(2))\n",
    "\n",
    "# ï¼ˆå¯é¸ï¼‰è¦†å¯«ä¿å­˜æ¸…ç†å¾Œçš„æ¨™è¨»æª”\n",
    "out_path = LABELED / \"for_annotation.cleaned.csv\"\n",
    "ann.to_csv(out_path, index=False)\n",
    "print(\"\\nâœ… å·²è¼¸å‡ºæ¸…ç†å¾Œæ¨™è¨»æª”ï¼š\", out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "24b150a0-3839-4bbb-8de9-2474697576a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train ä»½é‡ï¼š117\n",
      "Label\n",
      "real_apartment_review    106\n",
      "test_like                 10\n",
      "non_apartment              1\n",
      "Name: count, dtype: int64\n",
      "Label\n",
      "real_apartment_review    90.60\n",
      "test_like                 8.55\n",
      "non_apartment             0.85\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Val ä»½é‡ï¼š25\n",
      "Label\n",
      "real_apartment_review    20\n",
      "test_like                 5\n",
      "Name: count, dtype: int64\n",
      "Label\n",
      "real_apartment_review    80.0\n",
      "test_like                20.0\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Test ä»½é‡ï¼š11\n",
      "Label\n",
      "real_apartment_review    10\n",
      "test_like                 1\n",
      "Name: count, dtype: int64\n",
      "Label\n",
      "real_apartment_review    90.91\n",
      "test_like                 9.09\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "âœ… å·²è¼¸å‡ºï¼š\n",
      " - data/labeled/train.csv\n",
      " - data/labeled/val.csv\n",
      " - data/labeled/test.csv\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from pathlib import Path\n",
    "\n",
    "# ä»¥ complex_id åšç¾¤çµ„ï¼Œé¿å…åŒç¤¾å€åŒæ™‚åœ¨ train/val/test\n",
    "groups = ann[\"complex_id\"].astype(str)\n",
    "y = ann[\"Label\"]\n",
    "\n",
    "# train : temp(=val+test) = 80% : 20%\n",
    "gss1 = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "train_idx, temp_idx = next(gss1.split(ann, y, groups))\n",
    "\n",
    "train_df = ann.iloc[train_idx].copy()\n",
    "temp_df  = ann.iloc[temp_idx].copy()\n",
    "\n",
    "# temp å†åŠƒåˆ†æˆ val : test = 50% : 50%ï¼ˆå³å„ 10%ï¼‰\n",
    "gss2 = GroupShuffleSplit(n_splits=1, test_size=0.5, random_state=42)\n",
    "val_idx, test_idx = next(gss2.split(temp_df, temp_df[\"Label\"], temp_df[\"complex_id\"].astype(str)))\n",
    "\n",
    "val_df  = temp_df.iloc[val_idx].copy()\n",
    "test_df = temp_df.iloc[test_idx].copy()\n",
    "\n",
    "# ç¢ºèªåˆ†ä½ˆ\n",
    "def show_dist(name, d):\n",
    "    print(f\"\\n{name} ä»½é‡ï¼š{len(d)}\")\n",
    "    print(d[\"Label\"].value_counts())\n",
    "    print((d[\"Label\"].value_counts(normalize=True)*100).round(2))\n",
    "\n",
    "for nm, d in [(\"Train\",train_df),(\"Val\",val_df),(\"Test\",test_df)]:\n",
    "    show_dist(nm, d)\n",
    "\n",
    "# åŒ¯å‡º\n",
    "LABELED.mkdir(parents=True, exist_ok=True)\n",
    "train_df.to_csv(LABELED / \"train.csv\", index=False)\n",
    "val_df.to_csv(LABELED / \"val.csv\", index=False)\n",
    "test_df.to_csv(LABELED / \"test.csv\", index=False)\n",
    "print(\"\\nâœ… å·²è¼¸å‡ºï¼š\")\n",
    "print(\" - data/labeled/train.csv\")\n",
    "print(\" - data/labeled/val.csv\")\n",
    "print(\" - data/labeled/test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "322d1b9c-9cea-4569-bb80-cd3266499b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_csv(\"../data/labeled/train.csv\")\n",
    "val_df   = pd.read_csv(\"../data/labeled/val.csv\")\n",
    "test_df  = pd.read_csv(\"../data/labeled/test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f51b9262-cffe-496c-9bde-f4f2193bc9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®€å–æ¨™è¨»ä¾†æºï¼š /Users/tiffanytseng/Documents/ai-review-moderation-2/data/labeled/for_annotation.cleaned.csv\n",
      "ç¸½ç­†æ•¸ï¼š 153\n",
      "label\n",
      "real_apartment_review    136\n",
      "test_like                 17\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "ROOT = Path.cwd().parent\n",
    "LABELED = ROOT / \"data\" / \"labeled\"\n",
    "\n",
    "src_clean = LABELED / \"for_annotation.cleaned.csv\"\n",
    "src_raw   = LABELED / \"for_annotation.csv\"\n",
    "SRC = src_clean if src_clean.exists() else src_raw\n",
    "print(\"è®€å–æ¨™è¨»ä¾†æºï¼š\", SRC)\n",
    "\n",
    "ann = pd.read_csv(SRC)\n",
    "\n",
    "# æ¬„åæ­£è¦åŒ–\n",
    "ann.columns = [c.strip().lower().replace(\" \", \"_\") for c in ann.columns]\n",
    "\n",
    "# æª¢æŸ¥å¿…è¦æ¬„ä½\n",
    "need = {\"object_id\",\"complex_id\",\"review_text\",\"label\"}\n",
    "missing = need - set(ann.columns)\n",
    "if missing:\n",
    "    raise ValueError(f\"ç¼ºå°‘æ¬„ä½ï¼š{missing}\")\n",
    "\n",
    "# åƒ…äºŒé¡\n",
    "ann[\"label\"] = ann[\"label\"].astype(str).str.strip().str.lower().replace({\n",
    "    \"non-apartment\": \"test_like\",\n",
    "    \"non_apartment\": \"test_like\",\n",
    "    \"real-apartment-review\": \"real_apartment_review\",\n",
    "})\n",
    "allowed = {\"real_apartment_review\",\"test_like\"}\n",
    "ann = ann[ann[\"label\"].isin(allowed)].copy()\n",
    "\n",
    "print(\"ç¸½ç­†æ•¸ï¼š\", len(ann))\n",
    "print(ann[\"label\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "63c90b5f-3e5e-43de-9daf-7146ce825d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train: 117\n",
      "label\n",
      "real_apartment_review    106\n",
      "test_like                 11\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "real_apartment_review    90.6\n",
      "test_like                 9.4\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Val: 21\n",
      "label\n",
      "real_apartment_review    20\n",
      "test_like                 1\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "real_apartment_review    95.24\n",
      "test_like                 4.76\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Test: 15\n",
      "label\n",
      "real_apartment_review    10\n",
      "test_like                 5\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "real_apartment_review    66.67\n",
      "test_like                33.33\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "âœ… å·²è¼¸å‡º train/val/test åˆ° data/labeled/\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import numpy as np\n",
    "\n",
    "groups = ann[\"complex_id\"].astype(str)\n",
    "y = ann[\"label\"]\n",
    "\n",
    "def grouped_split(df, test_size=0.2, val_size=0.5, random_state=42, max_tries=100):\n",
    "    # å…ˆåˆ‡ train vs temp\n",
    "    for seed in range(random_state, random_state + max_tries):\n",
    "        gss1 = GroupShuffleSplit(n_splits=1, test_size=test_size, random_state=seed)\n",
    "        tr_idx, tmp_idx = next(gss1.split(df, df[\"label\"], df[\"complex_id\"].astype(str)))\n",
    "        train_df = df.iloc[tr_idx].copy()\n",
    "        tmp_df   = df.iloc[tmp_idx].copy()\n",
    "\n",
    "        # å†æŠŠ temp åˆ‡æˆ val/test\n",
    "        gss2 = GroupShuffleSplit(n_splits=1, test_size=val_size, random_state=seed+1)\n",
    "        v_idx, te_idx = next(gss2.split(tmp_df, tmp_df[\"label\"], tmp_df[\"complex_id\"].astype(str)))\n",
    "        val_df  = tmp_df.iloc[v_idx].copy()\n",
    "        test_df = tmp_df.iloc[te_idx].copy()\n",
    "\n",
    "        # ç¢ºä¿æ¯å€‹ split éƒ½åŒ…å«å…©é¡\n",
    "        ok = (set(train_df[\"label\"].unique()) == {\"real_apartment_review\",\"test_like\"} and\n",
    "              set(val_df[\"label\"].unique())   == {\"real_apartment_review\",\"test_like\"} and\n",
    "              set(test_df[\"label\"].unique())  == {\"real_apartment_review\",\"test_like\"})\n",
    "        if ok:\n",
    "            return train_df, val_df, test_df\n",
    "\n",
    "    raise RuntimeError(\"åˆ†çµ„æŠ½æ¨£å¤šæ¬¡ä»ç„¡æ³•è®“æ¯å€‹ split éƒ½å«å…©é¡ï¼›è«‹å¢åŠ æ¨£æœ¬æˆ–èª¿æ•´æ¯”ä¾‹ã€‚\")\n",
    "\n",
    "train_df, val_df, test_df = grouped_split(ann, test_size=0.2, val_size=0.5, random_state=42)\n",
    "\n",
    "def show_dist(name, d):\n",
    "    print(f\"\\n{name}: {len(d)}\")\n",
    "    print(d[\"label\"].value_counts())\n",
    "    print((d[\"label\"].value_counts(normalize=True)*100).round(2))\n",
    "\n",
    "show_dist(\"Train\", train_df)\n",
    "show_dist(\"Val\",   val_df)\n",
    "show_dist(\"Test\",  test_df)\n",
    "\n",
    "# åŒ¯å‡º\n",
    "train_df.to_csv(LABELED / \"train.csv\", index=False)\n",
    "val_df.to_csv(LABELED / \"val.csv\", index=False)\n",
    "test_df.to_csv(LABELED / \"test.csv\", index=False)\n",
    "print(\"\\nâœ… å·²è¼¸å‡º train/val/test åˆ° data/labeled/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8e2d427e-b645-4cb7-a397-7c60412e6d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== VAL ===\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "real_apartment_review       1.00      1.00      1.00        20\n",
      "            test_like       1.00      1.00      1.00         1\n",
      "\n",
      "             accuracy                           1.00        21\n",
      "            macro avg       1.00      1.00      1.00        21\n",
      "         weighted avg       1.00      1.00      1.00        21\n",
      "\n",
      "ROC-AUC(test_like): 1.0\n",
      "\n",
      "=== TEST ===\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "real_apartment_review       0.77      1.00      0.87        10\n",
      "            test_like       1.00      0.40      0.57         5\n",
      "\n",
      "             accuracy                           0.80        15\n",
      "            macro avg       0.88      0.70      0.72        15\n",
      "         weighted avg       0.85      0.80      0.77        15\n",
      "\n",
      "ROC-AUC(test_like): 0.96\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>real_apartment_review</th>\n",
       "      <th>test_like</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>real_apartment_review</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_like</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       real_apartment_review  test_like\n",
       "real_apartment_review                     10          0\n",
       "test_like                                  3          2"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "X_train, y_train = train_df[\"review_text\"].astype(str), train_df[\"label\"].astype(str)\n",
    "X_val,   y_val   = val_df[\"review_text\"].astype(str),   val_df[\"label\"].astype(str)\n",
    "X_test,  y_test  = test_df[\"review_text\"].astype(str),  test_df[\"label\"].astype(str)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(\n",
    "        ngram_range=(1,2),\n",
    "        min_df=2,\n",
    "        max_df=0.98,\n",
    "        sublinear_tf=True\n",
    "    )),\n",
    "    (\"clf\", LogisticRegression(\n",
    "        max_iter=2000,\n",
    "        class_weight=\"balanced\",\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "def eval_split(name, X, y):\n",
    "    pred = pipe.predict(X)\n",
    "    proba = pipe.predict_proba(X)[:, pipe.classes_.tolist().index(\"test_like\")]  # å– test_like çš„æ©Ÿç‡\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(classification_report(y, pred, target_names=[\"real_apartment_review\",\"test_like\"], zero_division=0))\n",
    "    try:\n",
    "        auc = roc_auc_score((y==\"test_like\").astype(int), proba)\n",
    "        print(\"ROC-AUC(test_like):\", round(auc, 4))\n",
    "    except Exception as e:\n",
    "        print(\"ROC-AUC ç„¡æ³•è¨ˆç®—ï¼š\", e)\n",
    "    return pred, proba\n",
    "\n",
    "pred_val,  proba_val  = eval_split(\"VAL\",  X_val,  y_val)\n",
    "pred_test, proba_test = eval_split(\"TEST\", X_test, y_test)\n",
    "\n",
    "# æ··æ·†çŸ©é™£ï¼ˆtestï¼‰\n",
    "cm = confusion_matrix(y_test, pred_test, labels=[\"real_apartment_review\",\"test_like\"])\n",
    "cm_df = pd.DataFrame(cm, index=[\"real_apartment_review\",\"test_like\"], columns=[\"real_apartment_review\",\"test_like\"])\n",
    "cm_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "66cfc5cc-4c7a-479e-8c04-aee5968f35b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æœªæ¨™è¨»æ± å¤§å°ï¼š 30355\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "ROOT = Path.cwd().parent\n",
    "PROC = ROOT / \"data\" / \"processed\"\n",
    "LABELED = ROOT / \"data\" / \"labeled\"\n",
    "\n",
    "clean_path = PROC / \"clean_no_gibberish_dups.csv\"\n",
    "ann_path   = LABELED / \"for_annotation.cleaned.csv\"\n",
    "\n",
    "pool = pd.read_csv(clean_path)\n",
    "pool.columns = [c.strip().lower().replace(\" \", \"_\") for c in pool.columns]\n",
    "\n",
    "if ann_path.exists():\n",
    "    ann = pd.read_csv(ann_path)\n",
    "else:\n",
    "    ann = pd.read_csv(LABELED / \"for_annotation.csv\")\n",
    "ann.columns = [c.strip().lower().replace(\" \", \"_\") for c in ann.columns]\n",
    "\n",
    "labeled_ids = set(ann[\"object_id\"].astype(str))\n",
    "pool = pool[~pool[\"object_id\"].astype(str).isin(labeled_ids)].copy()\n",
    "print(\"æœªæ¨™è¨»æ± å¤§å°ï¼š\", len(pool))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2b8375ce-10af-4a5b-9201-a0cc6eb116eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>object_id</th>\n",
       "      <th>complex_id</th>\n",
       "      <th>review_text</th>\n",
       "      <th>_proba_test_like</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5732</th>\n",
       "      <td>111700287</td>\n",
       "      <td>3101234567</td>\n",
       "      <td>x Be Specific - Don&amp;apos;t just complain about...</td>\n",
       "      <td>0.783889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26986</th>\n",
       "      <td>112082546</td>\n",
       "      <td>9199332346275143593</td>\n",
       "      <td>n/a ehh not applicableMillions of people use  ...</td>\n",
       "      <td>0.711205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6548</th>\n",
       "      <td>112685038</td>\n",
       "      <td>410356506221117</td>\n",
       "      <td>Please I don't want to complete this section.M...</td>\n",
       "      <td>0.686399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20064</th>\n",
       "      <td>217700</td>\n",
       "      <td>281890283977070</td>\n",
       "      <td>Not a great choice</td>\n",
       "      <td>0.681807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>112823250</td>\n",
       "      <td>9199332346275192547</td>\n",
       "      <td>JOE TEST Anon - Lorem ipsum dolor sit amet, co...</td>\n",
       "      <td>0.614671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       object_id           complex_id  \\\n",
       "5732   111700287           3101234567   \n",
       "26986  112082546  9199332346275143593   \n",
       "6548   112685038      410356506221117   \n",
       "20064     217700      281890283977070   \n",
       "270    112823250  9199332346275192547   \n",
       "\n",
       "                                             review_text  _proba_test_like  \n",
       "5732   x Be Specific - Don&apos;t just complain about...          0.783889  \n",
       "26986  n/a ehh not applicableMillions of people use  ...          0.711205  \n",
       "6548   Please I don't want to complete this section.M...          0.686399  \n",
       "20064                                 Not a great choice          0.681807  \n",
       "270    JOE TEST Anon - Lorem ipsum dolor sit amet, co...          0.614671  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# å–å¾— \"test_like\" åœ¨ pipe.classes_ çš„ index\n",
    "classes = pipe.classes_.tolist()\n",
    "assert \"test_like\" in classes, f\"ä½ çš„æ¨¡å‹é¡åˆ¥ï¼š{classes}ï¼Œæ‰¾ä¸åˆ° 'test_like'ã€‚\"\n",
    "ti = classes.index(\"test_like\")\n",
    "\n",
    "# å°æœªæ¨™è¨»æ± é æ¸¬\n",
    "proba = pipe.predict_proba(pool[\"review_text\"].astype(str))[:, ti]\n",
    "pool[\"_proba_test_like\"] = proba\n",
    "\n",
    "# æ–¹ä¾¿äººå·¥æ¨™è¨»çš„æ¬„ä½å­é›†\n",
    "view_cols = [\"object_id\",\"complex_id\",\"review_text\",\"_proba_test_like\"]\n",
    "pool_preview = pool[view_cols].copy().sort_values(\"_proba_test_like\", ascending=False)\n",
    "pool_preview.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ffa3da91-0f29-464c-b1b3-29bf8263f053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… å·²è¼¸å‡ºï¼š\n",
      " - /Users/tiffanytseng/Documents/ai-review-moderation-2/data/labeled/round2_candidates_highprob.csv\n",
      " - /Users/tiffanytseng/Documents/ai-review-moderation-2/data/labeled/round2_candidates_uncertain.csv\n",
      " - /Users/tiffanytseng/Documents/ai-review-moderation-2/data/labeled/round2_candidates_from_dropped.csv\n",
      "åˆè¨ˆå€™é¸ï¼š 0 + 200 + 200\n"
     ]
    }
   ],
   "source": [
    "# 1) é«˜æ©Ÿç‡ test_likeï¼ˆå»ºè­°å¿«é€Ÿæ¨™è¨˜ï¼šå¹¾ä¹éƒ½æ˜¯ï¼‰\n",
    "hi = pool_preview.query(\"_proba_test_like >= 0.80\").head(200)\n",
    "\n",
    "# 2) ä¸ç¢ºå®šå€ï¼ˆæ¨¡å‹æœ€éœ€è¦ä½ æä¾›è¨Šæ¯ï¼‰\n",
    "uncertain = pool_preview.query(\"_proba_test_like >= 0.40 and _proba_test_like <= 0.60\").head(200)\n",
    "\n",
    "# 3) å¾è¢«åˆªæ¸…å–®å›æ”¶ï¼ˆå¤šåŠæ˜¯äº‚æ–‡/æ¨¡æ¿ï¼‰\n",
    "dropped = pd.read_csv(PROC / \"_dropped_rows.csv\")\n",
    "dropped.columns = [c.strip().lower().replace(\" \", \"_\") for c in dropped.columns]\n",
    "pick_cols = [c for c in view_cols if c in dropped.columns] + [c for c in [\"_gibberish_score_v2\",\"_is_low_quality_v4\"] if c in dropped.columns]\n",
    "dropped_preview = dropped[pick_cols].copy()\n",
    "# å–äº‚æ–‡è¼ƒé«˜æˆ–è¢«æ¨™ç‚ºä½å“è³ªè€…\n",
    "if \"_gibberish_score_v2\" in dropped_preview:\n",
    "    backfill = dropped_preview.sort_values(\"_gibberish_score_v2\", ascending=False).head(200)\n",
    "else:\n",
    "    backfill = dropped_preview.head(200)\n",
    "\n",
    "# è¼¸å‡ºæˆå¾…æ¨™è¨» CSV\n",
    "LABELED.mkdir(parents=True, exist_ok=True)\n",
    "hi_out   = LABELED / \"round2_candidates_highprob.csv\"\n",
    "unc_out  = LABELED / \"round2_candidates_uncertain.csv\"\n",
    "drop_out = LABELED / \"round2_candidates_from_dropped.csv\"\n",
    "\n",
    "hi.to_csv(hi_out, index=False)\n",
    "uncertain.to_csv(unc_out, index=False)\n",
    "backfill.to_csv(drop_out, index=False)\n",
    "\n",
    "print(\"âœ… å·²è¼¸å‡ºï¼š\")\n",
    "print(\" -\", hi_out)\n",
    "print(\" -\", unc_out)\n",
    "print(\" -\", drop_out)\n",
    "print(\"åˆè¨ˆå€™é¸ï¼š\", len(hi), \"+\", len(uncertain), \"+\", len(backfill))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "76e0103d-adf6-4129-b3c5-1763b9693bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… å·²è¼¸å‡ºæ–°çš„æ¨™è¨»å…¨é›†ï¼š /Users/tiffanytseng/Documents/ai-review-moderation-2/data/labeled/for_annotation.cleaned.v2.csv\n",
      "label\n",
      "real_apartment_review    136\n",
      "test_like                 17\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "ROOT = Path.cwd().parent\n",
    "LABELED = ROOT / \"data\" / \"labeled\"\n",
    "\n",
    "# è®€åŸæ¨™è¨»\n",
    "base = pd.read_csv(LABELED / \"for_annotation.cleaned.csv\")\n",
    "base.columns = [c.strip().lower().replace(\" \", \"_\") for c in base.columns]\n",
    "\n",
    "# è®€å›åˆä½µ\n",
    "parts = []\n",
    "for name in [\"round2_labeled_highprob.csv\", \"round2_labeled_uncertain.csv\", \"round2_labeled_dropped.csv\"]:\n",
    "    p = LABELED / name\n",
    "    if p.exists():\n",
    "        d = pd.read_csv(p)\n",
    "        d.columns = [c.strip().lower().replace(\" \", \"_\") for c in d.columns]\n",
    "        # ç¢ºä¿æœ‰ label æ¬„\n",
    "        if \"label\" not in d.columns:\n",
    "            raise ValueError(f\"{name} ç¼ºå°‘ label æ¬„ä½\")\n",
    "        parts.append(d[[\"object_id\",\"complex_id\",\"review_text\",\"label\"]])\n",
    "\n",
    "add = pd.concat(parts, ignore_index=True) if parts else pd.DataFrame(columns=[\"object_id\",\"complex_id\",\"review_text\",\"label\"])\n",
    "\n",
    "# åˆä½µ & å»é‡ï¼ˆä»¥ text å»é‡ï¼‰\n",
    "merged = pd.concat([base[[\"object_id\",\"complex_id\",\"review_text\",\"label\"]], add], ignore_index=True)\n",
    "merged[\"label\"] = merged[\"label\"].astype(str).str.strip().str.lower().replace({\n",
    "    \"non-apartment\":\"test_like\",\"non_apartment\":\"test_like\",\n",
    "    \"real-apartment-review\":\"real_apartment_review\"\n",
    "})\n",
    "merged = merged.drop_duplicates(subset=[\"review_text\"]).copy()\n",
    "\n",
    "# è¦†å¯« cleaned v2\n",
    "out = LABELED / \"for_annotation.cleaned.v2.csv\"\n",
    "merged.to_csv(out, index=False)\n",
    "print(\"âœ… å·²è¼¸å‡ºæ–°çš„æ¨™è¨»å…¨é›†ï¼š\", out)\n",
    "print(merged[\"label\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0f979835-8a51-413f-9866-33d0a09f65b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== VAL ===\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "real_apartment_review       0.95      1.00      0.98        20\n",
      "            test_like       0.00      0.00      0.00         1\n",
      "\n",
      "             accuracy                           0.95        21\n",
      "            macro avg       0.48      0.50      0.49        21\n",
      "         weighted avg       0.91      0.95      0.93        21\n",
      "\n",
      "ROC-AUC(test_like): 1.0\n",
      "\n",
      "=== TEST ===\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "real_apartment_review       0.67      1.00      0.80        10\n",
      "            test_like       0.00      0.00      0.00         5\n",
      "\n",
      "             accuracy                           0.67        15\n",
      "            macro avg       0.33      0.50      0.40        15\n",
      "         weighted avg       0.44      0.67      0.53        15\n",
      "\n",
      "ROC-AUC(test_like): 0.96\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>real_apartment_review</th>\n",
       "      <th>test_like</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>real_apartment_review</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_like</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       real_apartment_review  test_like\n",
       "real_apartment_review                     10          0\n",
       "test_like                                  5          0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "ann = pd.read_csv(LABELED / \"for_annotation.cleaned.v2.csv\")\n",
    "ann.columns = [c.strip().lower().replace(\" \", \"_\") for c in ann.columns]\n",
    "\n",
    "# åˆ†çµ„åˆ‡åˆ†ï¼ˆç¢ºä¿æ¯å€‹ split å…©é¡éƒ½æœ‰ï¼‰\n",
    "def grouped_split(df, test_size=0.2, val_size=0.5, random_state=42, tries=100):\n",
    "    for seed in range(random_state, random_state+tries):\n",
    "        g1 = GroupShuffleSplit(n_splits=1, test_size=test_size, random_state=seed)\n",
    "        tr_idx, tmp_idx = next(g1.split(df, df[\"label\"], df[\"complex_id\"].astype(str)))\n",
    "        train_df, tmp_df = df.iloc[tr_idx].copy(), df.iloc[tmp_idx].copy()\n",
    "        g2 = GroupShuffleSplit(n_splits=1, test_size=val_size, random_state=seed+1)\n",
    "        v_idx, te_idx = next(g2.split(tmp_df, tmp_df[\"label\"], tmp_df[\"complex_id\"].astype(str)))\n",
    "        val_df, test_df = tmp_df.iloc[v_idx].copy(), tmp_df.iloc[te_idx].copy()\n",
    "        if all(set(d[\"label\"].unique())=={\"real_apartment_review\",\"test_like\"} for d in [train_df,val_df,test_df]):\n",
    "            return train_df, val_df, test_df\n",
    "    raise RuntimeError(\"ç„¡æ³•è®“æ¯å€‹ split éƒ½å«å…©é¡ï¼Œè«‹å¢åŠ æ¨£æœ¬æˆ–èª¿æ¯”ä¾‹ã€‚\")\n",
    "\n",
    "train_df, val_df, test_df = grouped_split(ann)\n",
    "\n",
    "X_train, y_train = train_df[\"review_text\"].astype(str), train_df[\"label\"].astype(str)\n",
    "X_val,   y_val   = val_df[\"review_text\"].astype(str),   val_df[\"label\"].astype(str)\n",
    "X_test,  y_test  = test_df[\"review_text\"].astype(str),  test_df[\"label\"].astype(str)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(ngram_range=(1,2), min_df=2, max_df=0.98, sublinear_tf=True)),\n",
    "    (\"clf\", LogisticRegression(max_iter=2000, class_weight={\"real_apartment_review\":0.8,\"test_like\":1.2}, n_jobs=-1))\n",
    "]).fit(X_train, y_train)\n",
    "\n",
    "def eval_split(name, X, y):\n",
    "    pred = pipe.predict(X)\n",
    "    proba = pipe.predict_proba(X)[:, pipe.classes_.tolist().index(\"test_like\")]\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(classification_report(y, pred, target_names=[\"real_apartment_review\",\"test_like\"], zero_division=0))\n",
    "    try:\n",
    "        print(\"ROC-AUC(test_like):\", round(roc_auc_score((y==\"test_like\").astype(int), proba), 4))\n",
    "    except: pass\n",
    "    return pred, proba\n",
    "\n",
    "pred_val,  proba_val  = eval_split(\"VAL\",  X_val,  y_val)\n",
    "pred_test, proba_test = eval_split(\"TEST\", X_test, y_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, pred_test, labels=[\"real_apartment_review\",\"test_like\"])\n",
    "pd.DataFrame(cm, index=[\"real_apartment_review\",\"test_like\"], columns=[\"real_apartment_review\",\"test_like\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "df523fff-948a-40f5-aa27-3d5e6fbdeaee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å­˜åœ¨æª¢æŸ¥ï¼š\n",
      "- for_annotation.cleaned.csv      exists=True  mtime=2025-10-22 15:08:56\n",
      "- round2_labeled_uncertain.csv    exists=False  mtime=N/A\n",
      "- round2_labeled_highprob.csv     exists=False  mtime=N/A\n",
      "- round2_labeled_dropped.csv      exists=False  mtime=N/A\n",
      "- for_annotation.cleaned.v2.csv   exists=True  mtime=2025-10-22 15:42:39\n",
      "\n",
      "âœ… v2 ç­†æ•¸ï¼š 153\n",
      "âœ… v2 æ¨™ç±¤åˆ†ä½ˆï¼š\n",
      "label\n",
      "real_apartment_review    136\n",
      "test_like                 17\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd, time\n",
    "\n",
    "ROOT = Path.cwd().parent\n",
    "LABELED = ROOT / \"data\" / \"labeled\"\n",
    "\n",
    "v2 = LABELED / \"for_annotation.cleaned.v2.csv\"\n",
    "base = LABELED / \"for_annotation.cleaned.csv\"\n",
    "r2u  = LABELED / \"round2_labeled_uncertain.csv\"\n",
    "r2h  = LABELED / \"round2_labeled_highprob.csv\"\n",
    "r2d  = LABELED / \"round2_labeled_dropped.csv\"\n",
    "\n",
    "def mtime(p): \n",
    "    return time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(p.stat().st_mtime)) if p.exists() else \"N/A\"\n",
    "\n",
    "print(\"å­˜åœ¨æª¢æŸ¥ï¼š\")\n",
    "for p in [base, r2u, r2h, r2d, v2]:\n",
    "    print(f\"- {p.name:30s}  exists={p.exists()}  mtime={mtime(p)}\")\n",
    "\n",
    "if v2.exists():\n",
    "    ann = pd.read_csv(v2)\n",
    "    ann.columns = [c.strip().lower().replace(\" \", \"_\") for c in ann.columns]\n",
    "    print(\"\\nâœ… v2 ç­†æ•¸ï¼š\", len(ann))\n",
    "    print(\"âœ… v2 æ¨™ç±¤åˆ†ä½ˆï¼š\")\n",
    "    print(ann[\"label\"].value_counts())\n",
    "else:\n",
    "    print(\"\\nâš ï¸ ç›®å‰æ²’æœ‰ v2ï¼Œä»£è¡¨åˆä½µæ­¥é©Ÿå°šæœªå®Œæˆï¼ˆæˆ–æ²’è¼¸å‡ºï¼‰ã€‚\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "71447c79-0a60-48e1-bbc9-360375f43bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train åˆ†ä½ˆï¼š\n",
      "label\n",
      "real_apartment_review    106\n",
      "test_like                 11\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Val åˆ†ä½ˆï¼š\n",
      "label\n",
      "real_apartment_review    20\n",
      "test_like                 1\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Test åˆ†ä½ˆï¼š\n",
      "label\n",
      "real_apartment_review    10\n",
      "test_like                 5\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "\n",
      "=== VAL ===\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "real_apartment_review       0.95      1.00      0.98        20\n",
      "            test_like       0.00      0.00      0.00         1\n",
      "\n",
      "             accuracy                           0.95        21\n",
      "            macro avg       0.48      0.50      0.49        21\n",
      "         weighted avg       0.91      0.95      0.93        21\n",
      "\n",
      "\n",
      "=== TEST ===\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "real_apartment_review       0.67      1.00      0.80        10\n",
      "            test_like       0.00      0.00      0.00         5\n",
      "\n",
      "             accuracy                           0.67        15\n",
      "            macro avg       0.33      0.50      0.40        15\n",
      "         weighted avg       0.44      0.67      0.53        15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "ann = pd.read_csv(LABELED / \"for_annotation.cleaned.v2.csv\")\n",
    "ann.columns = [c.strip().lower().replace(\" \", \"_\") for c in ann.columns]\n",
    "\n",
    "def grouped_split(df, test_size=0.2, val_size=0.5, random_state=42, tries=100):\n",
    "    for seed in range(random_state, random_state+tries):\n",
    "        g1 = GroupShuffleSplit(n_splits=1, test_size=test_size, random_state=seed)\n",
    "        tr_idx, tmp_idx = next(g1.split(df, df[\"label\"], df[\"complex_id\"].astype(str)))\n",
    "        train_df, tmp_df = df.iloc[tr_idx].copy(), df.iloc[tmp_idx].copy()\n",
    "        g2 = GroupShuffleSplit(n_splits=1, test_size=val_size, random_state=seed+1)\n",
    "        v_idx, te_idx = next(g2.split(tmp_df, tmp_df[\"label\"], tmp_df[\"complex_id\"].astype(str)))\n",
    "        val_df, test_df = tmp_df.iloc[v_idx].copy(), tmp_df.iloc[te_idx].copy()\n",
    "        if all(set(d[\"label\"].unique())=={\"real_apartment_review\",\"test_like\"} for d in [train_df,val_df,test_df]):\n",
    "            return train_df, val_df, test_df\n",
    "    raise RuntimeError(\"split ç„¡æ³•æ»¿è¶³æ¯çµ„å«å…©é¡ï¼Œè«‹å¢åŠ  test_like æˆ–èª¿æ•´æ¯”ä¾‹ã€‚\")\n",
    "\n",
    "train_df, val_df, test_df = grouped_split(ann)\n",
    "\n",
    "# æª¢æŸ¥å„ split çš„ test_like æ•¸é‡æ˜¯å¦çœŸçš„å¢åŠ \n",
    "for nm, d in [(\"Train\",train_df),(\"Val\",val_df),(\"Test\",test_df)]:\n",
    "    print(nm, \"åˆ†ä½ˆï¼š\")\n",
    "    print(d[\"label\"].value_counts(), \"\\n\")\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(ngram_range=(1,2), min_df=2, max_df=0.98, sublinear_tf=True)),\n",
    "    (\"clf\", LogisticRegression(max_iter=2000, class_weight={\"real_apartment_review\":0.8,\"test_like\":1.2}, n_jobs=-1))\n",
    "]).fit(train_df[\"review_text\"].astype(str), train_df[\"label\"].astype(str))\n",
    "\n",
    "def eval_split(name, X, y):\n",
    "    pred = pipe.predict(X)\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(classification_report(y, pred, target_names=[\"real_apartment_review\",\"test_like\"], zero_division=0))\n",
    "    return pred\n",
    "\n",
    "_ = eval_split(\"VAL\",  val_df[\"review_text\"].astype(str),  val_df[\"label\"].astype(str))\n",
    "_ = eval_split(\"TEST\", test_df[\"review_text\"].astype(str), test_df[\"label\"].astype(str))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa152bd-b611-465b-b552-a1015f56b335",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (.venv311)",
   "language": "python",
   "name": "ai311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
